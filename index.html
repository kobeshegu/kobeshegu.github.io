<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Mengping Yang">
  <meta name="description" content="Mengping Yang's Homepage">
  <meta name="keywords" content="Mengping Yang,杨孟平,homepage,主页,PhD,computer vision,GANs,ECUST,image generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mengping Yang (杨孟平)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Mengping Yang (杨孟平)</name>
              </p>
              <p style="text-align:center">
                kobeshegu[at]gmail.com &nbsp; &nbsp; <a href="https://scholar.google.com.hk/citations?user=yF34LtcAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;&nbsp;<a href="https://github.com/kobeshegu">Github</a> &nbsp;&nbsp;<a href="https://www.zhihu.com/people/ke-ke-ke-ke-ke-da-xia">Zhihu</a>  &nbsp;&nbsp;<a href="images/cv_ymp.pdf">CV</a>
              </p>
              <p>I am currently a Ph.D student (from Sep. 2019 - Jun. 2024 (Expected) ) at Ecust China University of Science and Technology (ECUST). My research interests mainly include multi-model learning/ AIGC, e.g., content generation of 2D images and videos, with Generative Adversarial Networks, Diffusion and auto-regressive models.
              </p>
              <p>
	           Before that, I received my B.S. from the Department of Computer Science and Technology with several honors in ECUST in Jul. 2019.
              </p>
              <p>
                I admire distinguished researchers/engineers who promote the advancement of the community, their fascinating projects inspire me a lot! 
                Hope that I can also make some impactful and insightful work!
              </p>
              <p>
              <strong> I am actively looking for a <font color="red">long-term intern/collabration/full-time job opportunities (available from Sep. 2023), working on fundamental research and application related problems of generative models</font>. Here is my <a href="images/cv_ymp.pdf">CV</a>, feel free to email me for any potential opportunities! </strong>
              </p>
		    
            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/mengping.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/mengping.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
  
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <ul style="font-size: 12pt; text-align: justify;">
             <li><strong>[03/2024]</strong>
              <font color="black" size="3"> Three collabrated paper respectively got accepted by CVPR-2024, PR, EAAI, congrats to co-authors. </font>
             <li><strong>[01/2024]</strong>
              <font color="black" size="3"> Honored to win the grand prize of president's scholarship (one student per year). </font>
             <li><strong>[10/2023]</strong>
              <font color="black" size="3"> One collabrated paper got accepted by KBS, congrats to Zhiling. </font>
             <li><strong>[09/2023]</strong>
              <font color="black" size="3"> One paper got accepted by NeurIPS Datasets and Benchmarks Track. </font>
              <font color="red">Many thanks to my collabrators!</font>
             <li><strong>[09/2023]</strong>
              <font color="black" size="3"> One paper got accepted by EAAI. </font>
             <li><strong>[08/2023]</strong>
              <font color="black" size="3"> One survey paper on image synthesis under limited data released to </a>&nbsp;<a href="https://arxiv.org/abs/2307.16879">ArXiv</a>. </font>
             <li><strong>[07/2023]</strong>
              <font color="black" size="3"> Two papers got accepted by ACM Multimedia 2023. </font>
            <li><strong>[04/2023]</strong>
              <font color="black" size="3"> One paper on evaluating synthesis quality released to </a>&nbsp;<a href="https://arxiv.org/abs/2304.01999">ArXiv</a>. </font>
            <li><strong>[03/2023]</strong>
              <font color="black" size="3"> One paper got accepted by Information Sciences. </font>
            <li><strong>[11/2022]</strong>
              <font color="black" size="3"> I was honored to present our blessings at </a> &nbsp;&nbsp;<a href="https://news.ecust.edu.cn/2022/1031/c160a169108/page.htm">ECUST's 70th anniversary celebration</a>. <strong> Happy birthday! </strong> </font>
            <li><strong>[10/2022]</strong>
              <font color="black" size="3"> One paper got accepted by EAAI. </font>
            <li><strong>[09/2022]</strong>
              <font color="black" size="3"> One paper got accepted by NeurIPS 2022. </font>
            <li><strong>[07/2022]</strong>
              <font color="black" size="3"> One paper got accepted by ECCV 2022. </font> 
              <font color="red">This is my first top-tier conference paper!</font>
            <li><strong>[05/2022]</strong>
              <font color="black" size="3"> One paper got accepted by IJCAI 2022. </font>
            </li>
          </ul>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/CVPR-2024.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="metric" src="images/CVPR-2024.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Attention Calibration for Disentangled Text-to-Image Personalization</papertitle>
              <br>
              Yanbing Zhang, <strong>Mengping Yang</strong> <font color="red">(Student Project Lead)</font>, Qin Zhou, Zhe Wang*
              <br>
              <em>CVPR</em> 2024, <font color="red"> (Oral Presentation)</font>,
              <br>
              <a href="https://openreview.net/group?id=thecvf.com/CVPR/2024/Conference/Authors&referrer=%5BHomepage%5D(%2F)">[PDF]</a>
              <a href="images/CVPR-2024.txt">[BibTeX]</a>
              <br>
              <p>We propose an attention calibration mechanism to improve the concept-level understanding of the T2I model. Specifically, we first introduce new learnable modifiers bound with classes to capture attributes of multiple concepts. Then, the classes are separated and strengthened following the activation of the cross-attention operation, ensuring comprehensive and self-contained concepts. Additionally, we suppress the attention activation of different classes to mitigate mutual influence among concepts. </p>
          </td>
      </tr> 

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/metric.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="metric" src="images/metric.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Revisiting the Evaluation of Image Synthesis with GANs</papertitle>
              <br>
              <strong>Mengping Yang*</strong>, Ceyuan Yang*, Yichi Zhang, Qingyan Bai, Yujun Shen, Bo Dai
              <br>
              <em>NeruIPS Datasets and Benchmarks</em> 2023,
              <br>
              <a href="https://arxiv.org/abs/2304.01999">[PDF]</a>
              <a href="images/metric.txt">[BibTeX]</a>
              <br>
              <p>We make in-depth analyses on how to represent a data point in the feature space, how to calculate a fair distance using selected samples, and how many instances to use from each set. 
                Together with these analysis, we build a comprehensive system for synthesis comparison.</p>
          </td>
      </tr> 

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/survey.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="survey" src="images/survey.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Image Synthesis under Limited Data: A Survey and Taxonomy</papertitle>
              <br>
              <strong>Mengping Yang</strong>, Zhe Wang*
              <br>
              <em>ArXiv</em> 2023,
              <br>
              <a href="https://arxiv.org/abs/2307.16879">[PDF]</a>
              <a href="https://github.com/kobeshegu/awesome-few-shot-generation">[Project]</a>
              <a href="images/survey.txt">[BibTeX]</a>
              <br>
              <p>We provide a comprehensive survey on image synthesis under limited data, including data-efficient generative modeling, few-shot generative adaptation, few-shot and one-shot image synthesis.</p>
          </td>
      </tr> 

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/modulateD.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="modulateD" src="images/modulateD.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Improving Few-shot Image Generation by Structural Discrimination and Textural Modulation</papertitle>
              <br>
              <strong>Mengping Yang</strong>, Zhe Wang*, Wenyi Feng, Qian Zhang, Ting Xiao
              <br>
              <em>ACM MM</em> 2023,
              <br>
              <a href="https://arxiv.org/pdf/2308.16110.pdf">[PDF]</a>
              <a href="https://github.com/kobeshegu/SDTM-GAN-ACMMM-2023">[Project]</a>
              <a href="images/modulateD.txt">[BibTeX]</a>
              <br>
              <p>We propose textural modulation (TexMod) and strctural discriminator (StructD) for improving the performance of few-shot image generaion.</p>
          </td>
      </tr> 

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/mmguan.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="mmguan" src="images/mmguan.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Semantic-Aware Generator and Low-level Feature Augmentation for Few-shot Image Generation</papertitle>
              <br>
              Zhe Wang*, Jiaoyan Guan, <strong>Mengping Yang</strong> <font color="red">(Student Project Lead)</font>, Ting Xiao, Ziqiu Chi
              <br>
              <em>ACM MM</em> 2023,
              <br>
              <a href="https://doi.org/10.1145/3581783.3611763">[PDF]</a>
              <a href="images/mmguan.txt">[BibTeX]</a>
              <br>
              <p>We propose semantic-aware generator (SAG) and low-level feature augmentation (LFA) for improving the performance of few-shot image generaion.</p>
          </td>
      </tr> 


        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/protogan.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="protogan" src="images/protogan.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>ProtoGAN: Towards high diversity and fidelity image synthesis under limited data</papertitle>
              <br>
              <strong>Mengping Yang</strong>, Zhe Wang, Ziqiiu Chi, Wenli Du
              <br>
              <em>InS</em> 2023,
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S0020025523003389">[PDF]</a>
              <a href="images/protogan.txt">[BibTeX]</a>
              <br>
              <p> we propose ProtoGAN, a GAN that incorporates the metric-learning-based prototype mechanism into adversarial learning by aligning the prototypes and features of synthesized distribution and the real distribution.</p>
          </td>
      </tr> 

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/dfsgan.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="dfsgan" src="images/dfsgan.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>DFSGAN: Introducing editable and representative attributes for few-shot image generation</papertitle>
                <br>
                <strong>Mengping Yang</strong>, Saisai Niu, Zhe Wang, Dongdong Li, Wenli Du
                <br>
                <em>EAAI</em> 2023,
                <br>
                <a href="https://www.sciencedirect.com/science/article/pii/S0952197622005097">[PDF]</a>
                <a href="images/dfsgan.txt">[BibTeX]</a>
                <br>
                <p> we propose DFSGAN for few-shot image generation, which takes dynamic Gaussian mixture (DGM) latent codes as the generator’s input.</p>
            </td>
        </tr> 
	
        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/fregan.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="fregan" src="images/fregan.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>FreGAN: Exploiting Frequency Components for Training GANs under Limited Data</papertitle>
                <br>
                <strong>Mengping Yang</strong>, Zhe Wang, Ziqiu Chi, Yanbing Zhang
                <br>
                <em>NeurIPS</em> 2022,
                <br>
                <a href="https://arxiv.org/abs/2210.05461">[PDF]</a>
                <a href="https://github.com/kobeshegu/FreGAN_NeurIPS2022/">[Project]</a>
		            <a href="images/fregan.txt">[BibTeX]</a>
                <br>
                <p>We propose a frequency-aware model for training GANs under limited data, facilitating high-quality few-shot image syntheisi.</p>
            </td>
        </tr>		

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/wavegan.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="wavegan" src="images/wavegan.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>WaveGAN: Frequency-Aware GAN for High-Fidelity Few-Shot Image Generation</papertitle>
                <br>
                <strong>Mengping Yang</strong>, Zhe Wang, Ziqiu Chi, Yanbing Zhang
                <br>
                <em>ECCV</em> 2022,
                <br>
                <a href="https://arxiv.org/pdf/2207.07288">[PDF]</a>
                <a href="https://github.com/kobeshegu/ECCV2022_WaveGAN/">[Project]</a>
                <a href="images/wavegan.txt">[BibTeX]</a>
                <br>
                <p>We propose a frequency-aware model for few-shot image generation, enabling high-fidelity synthesis for downstream tasks.</p>
            </td>
        </tr>  

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/ijcai.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="ijcai" src="images/ijcai.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Better Embedding and More Shots for Few-shot Learning</papertitle>
                <br>
                Ziqiu Chi, Zhe Wang, <strong>Mengping Yang</strong>, Wei Guo, Xinlei Xu
                <br>
                <em>IJCAI</em> 2022,
                <br>
                <a href="https://www.ijcai.org/proceedings/2022/0398.pdf">[PDF]</a>
                <br>
                <p>We develop Better Embedding and More Shots to address the distorted embedding of target data in few-shot learning.</p>
            </td>
        </tr>    

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/ncaa.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="ncaa" src="images/ncaa.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Gravitation balanced multiple kernel learning for imbalanced classification</papertitle>
                <br>
                <strong>Mengping Yang</strong>, Zhe Wang, Yanqiong Li, Yangming Zhou, Dongdong Li, Wenli Du
                <br>
                <em>NCAA</em> 2022,
                <br>
                <a href="https://link.springer.com/article/10.1007/s00521-022-07187-4">[PDF]</a>
                <br>
                <p>We propose gravitational balanced multiple kernel learning (GBMKL) method for imbalanced classification.</p>
            </td>
        </tr>   

    </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experiences</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one" >
                <a href="images/shlab.png"><img style="width:100%;max-width:100%; position: absolute;top: -5%" alt="shlab" src="images/shlab.png" class="hoverZoomLink"></a>
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Research intern</papertitle>
                <br>
                Working on fundamental research problems and potential applications of deep generative models, mainly GANs and Diffusion Models.
                <br>
                Mentor: Dr. <a href="https://ceyuan.me">Ceyuan Yang</a> and Dr. <a href="https://daibo.info">Bo Dai</a>
                <br>
                2022.07.19 —— 2023.07.19
            </td>
        </tr>  
    

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Honors & Awards</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <ul style="font-size: 12pt; text-align: justify;">
          <li> Grand prize of president's scholarship (one student per year), <div style="float:right; text-align:right">2023</div>
          </li>
          <li> First Class Scholarship of Graduate, <div style="float:right; text-align:right">2019-2024</div>
          </li>
          <li> Shanghai Sparkling Youth, <a href="https://news.ecust.edu.cn/2022/1224/c160a170282/page.htm">[Only one in ECUST!]</a> <div style="float:right; text-align:right">2022</div>
          </li>
          <li> Jiangxi Building Material Scholarship, <div style="float:right; text-align:right">2021</div>
          </li>
          <li> Suzhou Industrial Park Scholarship, <div style="float:right; text-align:right">2022</div>
          </li>
          <li> Chinese University Student of the Year <a href="https://news.ecust.edu.cn/2021/0105/c6a157857/page.htm">[Only 20 students per year in among all college students]</a>, <div style="float:right; text-align:right">2020</div>
          </li>
          <li> Outstanding students, <div style="float:right; text-align:right">2016-2024</div>
          </li>
          <li> Second Prize of Mathematics Competition of Chinese Graduate Students, <div
              style="float:right; text-align:right">2020</div>
          </li>
        </ul>
        <!-- </font> -->
    
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Professional activities</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <ul style="font-size: 12pt; text-align: justify;">
          <li>Conference Reviewer for CVPR(2023, 2024), NeurIPS(2023), IJCAI(2022), ACMMM(2023, 2024)</li>
          <li>Journal Reviewer for TPAMI, TCSVT</li>
        </ul>
        <!-- </font> -->

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misk</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <!-- <font face="helvetica, ariel, 'sans serif'">  -->
        <ul style="font-size: 12pt; text-align: justify;">
          <li>I like reading books (mostly Social Sciences and Philosophy), watching movies (mainly Sci-Fi, Martial Arts Chivalry) during free time. </li>
          <li>I used to playing basketball a lot (once a week at present), Kobe Bryant is my favorite, always GOAT in my heart.</li>
        </ul>
        <!-- </font> -->


        <tr></tr>
            <td style="padding:20px;width:0%;vertical-align:middle">
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
        <hr style="margin-top:0px">
                <p>The website template was adapted from <a href="https://jonbarron.info/">Jon Barron</a> and  <a href="https://yudeng.github.io/">Yu Deng</a>.</p>
            </td>
              <p>This page has been accessed <a href="http://stuff.mit.edu/doc/counter-howto.html"><img src="http://stuff.mit.edu/cgi/counter/kobeshegu" alt="several"></a> times since Feb 2022.
              </p>
        </tr>

      </td>
    </tr>
  </table>
</body>

</html>
